{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  ISUZU IntelliChat\n",
    "An intelliChat, conversational AI chatbot for enhanced customer engagement and support powered by Large Language Models (LLMs)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Project Goal\n",
    "To develop a state-of-the-art chatbot tailored for ISUZU that can assist with customer queries, vehicle recommendations, service scheduling, troubleshooting, and general brand interaction. The chatbot will be deployed steamlit for agents interactions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Project Flow\n",
    "#### Problem Definition\n",
    "<b> Objective </b>: Build an intuitive chatbot that aligns with ISUZU‚Äôs brand values: reliability, innovation, and customer satisfaction.\n",
    "\n",
    "<i>Primary Use Cases</i>:\n",
    "* <i> Vehicle Recommendations</i>: Help associates recommend the right ISUZU vehicle based on customers preferences and budget.\n",
    "* <i> Customer Support</i>: Answer FAQs about vehicles, maintenance, and services.\n",
    "* <i> Service Scheduling</i>: Assist Associates in booking vehicle services or repairs.\n",
    "* <i> Dealer Locator</i>: Help customers find the nearest dealerships or service centers.\n",
    "* <i> Lead Generation</i>: Collect potential customer information for follow-ups."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset Preparation\n",
    "#### Data Sources:\n",
    "\n",
    "<ol>\n",
    "<li>ISUZU‚Äôs existing customer FAQs</li>\n",
    "<li> training and support documents </li>\n",
    "<li>Vehicle specification sheets</li>\n",
    "<li>Brochures, and catalogs</li>\n",
    "<li>Customer interaction logs (emails, chats, calls)</li>\n",
    "<li>ISUZU‚Äôs website and marketing materials</li>\n",
    "<li>Feedback from customer surveys</li>\n",
    "</ol>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Processing:\n",
    "\n",
    "<ol>\n",
    "<li> Clean and standardize textual data</li>\n",
    "<li> Annotate intents (e.g., ‚Äúservice booking,‚Äù ‚Äúvehicle specs query‚Äù)</li>\n",
    "<li> Categorize entities like vehicle models, features, locations, and service types</li>\n",
    "</ol>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data injection_____"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Selection\n",
    "##### LLM Selection:\n",
    "*  OpenAI GPT-4 or Anthropic Claude for their ability to handle complex and domain-specific conversations.\n",
    "*  Hugging Face BLOOM or Meta‚Äôs LLaMA for open-source options if cost-efficiency is a priority.\n",
    "\n",
    "<b>Fine-Tuning </b>:\n",
    "\n",
    "Fine-tune the LLM on ISUZU-specific data to ensure domain expertise.\n",
    "Use transfer learning to teach the model vehicle-related terminology, common queries, and ISUZU‚Äôs brand tone.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conversational Flow Design\n",
    "##### Key Components:\n",
    "* Intents: Vehicle recommendations, service booking, troubleshooting, etc.\n",
    "* Entities: Vehicle models, features, service center locations, dates, times.\n",
    "#### Dialogue Flow:\n",
    "* User: ‚ÄúWhich ISUZU vehicle is best for off-roading?‚Äù\n",
    "* Chatbot: ‚ÄúThe ISUZU D-Max is an excellent choice for off-roading, thanks to its advanced 4WD system and rugged build. Would you like to learn more about its features?‚Äù\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Loading the libraries "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import streamlit as st\n",
    "import pickle\n",
    "import time\n",
    "import faiss\n",
    "\n",
    "from langchain import OpenAI\n",
    "from langchain.chains import RetrievalQAWithSourcesChain\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain.document_loaders import TextLoader\n",
    "from langchain.embeddings import OpenAIEmbeddings\n",
    "from langchain.vectorstores import FAISS\n",
    "from llama_index.core import SimpleDirectoryReader\n",
    "from langchain_core.documents import Document  # Import LangChain's Document class"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### üîπ Set OpenAI API Key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "import os\n",
    "OPENAI_API_KEY: str= os.getenv(\"OPENAI_API_KEY\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### üîπ Initialize OpenAI LLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Thomas.Okiwi\\AppData\\Local\\Temp\\ipykernel_16208\\2312513075.py:2: LangChainDeprecationWarning: The class `OpenAI` was deprecated in LangChain 0.0.10 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-openai package and should be used instead. To use it run `pip install -U :class:`~langchain-openai` and import as `from :class:`~langchain_openai import OpenAI``.\n",
      "  llm = OpenAI(temperature=0.9, max_tokens=500)\n"
     ]
    }
   ],
   "source": [
    "# üîπ Initialize OpenAI LLM\n",
    "llm = OpenAI(temperature=0.9, max_tokens=500)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### üîπ Loading Documents "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Failed to load file C:\\Users\\Thomas.Okiwi\\OneDrive - Techno Brain Group\\Documents\\Data Science Projects\\Generative AI\\IsuuBot\\Data\\Body price.csv with error: 'utf-8' codec can't decode byte 0x96 in position 79: invalid start byte. Skipping...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Ignoring wrong pointing object 18 0 (offset 0)\n",
      "Ignoring wrong pointing object 20 0 (offset 0)\n",
      "Ignoring wrong pointing object 91 0 (offset 0)\n",
      "Ignoring wrong pointing object 18 0 (offset 0)\n",
      "Ignoring wrong pointing object 20 0 (offset 0)\n",
      "Ignoring wrong pointing object 91 0 (offset 0)\n",
      "Ignoring wrong pointing object 18 0 (offset 0)\n",
      "Ignoring wrong pointing object 20 0 (offset 0)\n",
      "Ignoring wrong pointing object 91 0 (offset 0)\n"
     ]
    }
   ],
   "source": [
    "# üîπ Load documents from the directory using LlamaIndex\n",
    "folder_path = r\"C:\\Users\\Thomas.Okiwi\\OneDrive - Techno Brain Group\\Documents\\Data Science Projects\\Generative AI\\IsuuBot\\Data\"\n",
    "llama_documents = SimpleDirectoryReader(folder_path).load_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### üîπ Convert LlamaIndex documents to LangChain-compatible format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# üîπ Convert LlamaIndex documents to LangChain-compatible format with metadata\n",
    "langchain_documents = []\n",
    "for doc in llama_documents:\n",
    "    langchain_documents.append(Document(page_content=doc.text, metadata={\"source\": doc.doc_id}))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### üîπ Create a text splitter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# üîπ Create a text splitter\n",
    "text_splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size=800,\n",
    "    chunk_overlap=100\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Total Chunks Created: 1165\n",
      "‚úÖ Total Documents Loaded: 499\n"
     ]
    }
   ],
   "source": [
    "# üîπ Split the documents into chunks\n",
    "split_docs = text_splitter.split_documents(langchain_documents)\n",
    "\n",
    "# Print the number of chunks\n",
    "print(f\"‚úÖ Total Chunks Created: {len(split_docs)}\")\n",
    "print(f\"‚úÖ Total Documents Loaded: {len(llama_documents)}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### üîπ Create Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Thomas.Okiwi\\AppData\\Local\\Temp\\ipykernel_16208\\846761174.py:2: LangChainDeprecationWarning: The class `OpenAIEmbeddings` was deprecated in LangChain 0.0.9 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-openai package and should be used instead. To use it run `pip install -U :class:`~langchain-openai` and import as `from :class:`~langchain_openai import OpenAIEmbeddings``.\n",
      "  embeddings = OpenAIEmbeddings()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ FAISS Index Saved Successfully!\n"
     ]
    }
   ],
   "source": [
    "# üîπ Initialize OpenAI Embeddings\n",
    "embeddings = OpenAIEmbeddings()\n",
    "\n",
    "# üîπ Create FAISS Vector Store\n",
    "vector_store = FAISS.from_documents(split_docs, embeddings)\n",
    "\n",
    "# üîπ Save FAISS Index\n",
    "faiss_index_path = \"vector_index.faiss\"\n",
    "faiss.write_index(vector_store.index, faiss_index_path)\n",
    "print(\"‚úÖ FAISS Index Saved Successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ FAISS Index Loaded Successfully!\n"
     ]
    }
   ],
   "source": [
    "# üîπ Load the FAISS index\n",
    "index = faiss.read_index(faiss_index_path)\n",
    "\n",
    "# Check if the index is loaded correctly\n",
    "if index.is_trained:\n",
    "    print(\"‚úÖ FAISS Index Loaded Successfully!\")\n",
    "else:\n",
    "    print(\"‚ùå FAISS Index Loading Failed!\")\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### üîπ Creating a Retriever"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# üîπ Wrap FAISS with LangChain's retriever\n",
    "retriever = vector_store.as_retriever()\n",
    "\n",
    "# üîπ Create the RetrievalQA Chain\n",
    "qa_chain = RetrievalQAWithSourcesChain.from_llm(llm=llm, retriever=retriever)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### üîπ Queries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üîπ Query:  How much is the deposit and the monthly payment ? \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Thomas.Okiwi\\AppData\\Local\\Temp\\ipykernel_16208\\91349922.py:11: LangChainDeprecationWarning: The method `Chain.__call__` was deprecated in langchain 0.1.0 and will be removed in 1.0. Use :meth:`~invoke` instead.\n",
      "  response = qa_chain({\"question\": query})\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîπ Answer:  The deposit is 5% of the vehicle price and it can change depending on the amount of financing you will get. The monthly payment information is not specified.\n",
      "\n",
      "üîπ Sources: 8406bf16-3ccb-407c-b164-15180ff4404c\n"
     ]
    }
   ],
   "source": [
    "# üîπ Example Queries\n",
    "example_queries = [\n",
    "    \" How much is the deposit and the monthly payment ? \"\n",
    "  \n",
    "]\n",
    "\n",
    "\n",
    "# üîπ Run example queries\n",
    "for query in example_queries:\n",
    "    print(\"\\nüîπ Query:\", query)\n",
    "    response = qa_chain({\"question\": query})\n",
    "    print(\"üîπ Answer:\", response[\"answer\"])\n",
    "    print(\"üîπ Sources:\", response.get(\"sources\", \"No sources found\"))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Deployment "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "## http://localhost:8501/"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (learn-env)",
   "language": "python",
   "name": "learn-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
